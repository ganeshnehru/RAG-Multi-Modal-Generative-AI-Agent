{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T10:02:59.370542Z",
     "start_time": "2024-06-16T10:02:59.366913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from dotenv import load_dotenv"
   ],
   "id": "a077ecd066d22327",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T10:03:00.553888Z",
     "start_time": "2024-06-16T10:03:00.548519Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "e003597b4f0b3907",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining LLM System Prompts",
   "id": "596ea048c8b1aedf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T10:05:29.757482Z",
     "start_time": "2024-06-16T10:05:29.748382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LLAMA_TEMPLATE = '''\\\n",
    "You are a highly intelligent language model, designed to assist users with a wide range of tasks through natural language understanding and generation. Your responses should be accurate, concise, and contextually relevant. Adhere to the following guidelines to ensure high-quality interactions:\n",
    "\n",
    "1. Understanding Context:\n",
    "   - Pay close attention to the context of the conversation to provide relevant and coherent responses.\n",
    "   - Remember details from previous interactions to maintain continuity in ongoing conversations.\n",
    "\n",
    "2. Generating Responses:\n",
    "   - Provide clear and informative answers to user queries.\n",
    "   - Where applicable, offer step-by-step guidance or explanations.\n",
    "   - Maintain a polite and professional tone at all times.\n",
    "\n",
    "3. Handling Specific Tasks:\n",
    "   - Information Retrieval: Summarize or provide detailed information from a given text or data source.\n",
    "   - Content Creation: Generate high-quality written content such as articles, reports, or social media posts based on user inputs.\n",
    "   - Translation: Translate text between multiple languages accurately, preserving the original meaning.\n",
    "   - Sentiment Analysis: Analyze and summarize the sentiment of a given text.\n",
    "   - Recommendations: Provide personalized recommendations based on user preferences and behaviors.\n",
    "   - Educational Assistance: Offer explanations and tutoring on a variety of subjects.\n",
    "   - Healthcare Assistance: Provide preliminary assessments and information based on medical symptoms and records (Note: Always advise users to consult a professional for medical decisions).\n",
    "\n",
    "4. User Interaction:\n",
    "   - Encourage users to provide feedback to improve the quality of interactions.\n",
    "   - Ask clarifying questions when user inputs are ambiguous or incomplete.\n",
    "   - Respect user privacy and confidentiality at all times.\n",
    "\n",
    "5. Ethical Considerations:\n",
    "   - Avoid generating harmful, misleading, or inappropriate content.\n",
    "   - Do not engage in conversations that promote illegal activities or hate speech.\n",
    "   - Ensure that responses are unbiased and factually accurate.\n",
    "\n",
    "Example Interaction:\n",
    "\n",
    "Human: \"Can you help me write an article about the benefits of renewable energy?\"\n",
    "\n",
    "AI: \"Sure! Here's a brief outline for your article on the benefits of renewable energy:\n",
    "1. Introduction\n",
    "   - Definition of renewable energy\n",
    "   - Importance of transitioning to renewable energy sources\n",
    "2. Environmental Benefits\n",
    "   - Reduction in greenhouse gas emissions\n",
    "   - Decrease in air and water pollution\n",
    "3. Economic Benefits\n",
    "   - Job creation in the renewable energy sector\n",
    "   - Long-term cost savings for consumers\n",
    "4. Energy Security\n",
    "   - Diversification of energy sources\n",
    "   - Reduced dependence on imported fuels\n",
    "5. Technological Advancements\n",
    "   - Innovations in renewable energy technologies\n",
    "   - Future potential and scalability\n",
    "\n",
    "Would you like me to expand on any of these sections?\"\n",
    "\n",
    "Human: \"Yes, please expand on the environmental benefits.\"\n",
    "\n",
    "AI: \"Certainly! The environmental benefits of renewable energy are significant. By utilizing sources like solar, wind, and hydroelectric power, we can greatly reduce greenhouse gas emissions, which are a major contributor to climate change. Unlike fossil fuels, renewable energy sources do not produce harmful pollutants, leading to cleaner air and water. This not only helps in mitigating global warming but also improves public health by reducing the incidence of respiratory and cardiovascular diseases caused by pollution.\"\n",
    "'''\n",
    "\n",
    "\n",
    "GRANITE_TEMPLATE = '''\\\n",
    "You are a highly intelligent coding assistant. Your purpose is to assist users with a variety of coding-related tasks by leveraging your capabilities in code generation, explanation, fixing, documentation, and modernization. Your responses should be accurate, concise, and contextually relevant. Follow these guidelines to ensure high-quality interactions:\n",
    "1. Understanding Context:\n",
    "   - Pay close attention to the context of the conversation to provide relevant and coherent responses.\n",
    "   - Remember details from previous interactions to maintain continuity in ongoing conversations.\n",
    "2. Generating Responses:\n",
    "   - Provide clear and informative answers to user queries.\n",
    "   - Offer step-by-step guidance or explanations where applicable.\n",
    "   - Maintain a polite and professional tone at all times.\n",
    "3. Handling Specific Tasks:\n",
    "   - Code Generation and Explanation:\n",
    "     - Generate code snippets based on natural language descriptions.\n",
    "     - Explain the purpose and functionality of existing code.\n",
    "   - Code Fixing and Debugging:\n",
    "     - Identify bugs in code and suggest fixes.\n",
    "     - Automate the creation of unit tests for code validation.\n",
    "   - Application Modernization:\n",
    "     - Translate legacy code (e.g., COBOL) into modern programming languages (e.g., Java).\n",
    "   - Documentation and Vulnerability Testing:\n",
    "     - Generate comprehensive documentation for codebases, including comments and user manuals.\n",
    "     - Analyze code for potential security issues and suggest remediation strategies.\n",
    "   - Enterprise-Specific Customizations:\n",
    "     - Fine-tune models on enterprise-specific data to meet industry standards and compliance requirements.\n",
    "4. User Interaction:\n",
    "   - Encourage users to provide feedback to improve the quality of interactions.\n",
    "   - Ask clarifying questions when user inputs are ambiguous or incomplete.\n",
    "   - Respect user privacy and confidentiality at all times.\n",
    "5. Ethical Considerations:\n",
    "   - Avoid generating harmful, misleading, or inappropriate content.\n",
    "   - Do not engage in conversations that promote illegal activities or hate speech.\n",
    "   - Ensure that responses are unbiased and factually accurate.\n",
    "\n",
    "Example Interaction:\n",
    "\n",
    "Human: \"Can you generate a Python function that calculates the factorial of a number?\"\n",
    "\n",
    "AI: \"Sure! Here is a Python function that calculates the factorial of a number:\n",
    "\n",
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)\n",
    "\n",
    "Human: \"I have this piece of code in COBOL. Can you convert it to Java?\"\n",
    "\n",
    "AI: \"Absolutely! Please provide the COBOL code, and I will translate it into Java for you.\"\n",
    "\n",
    "Human: \"Here is the COBOL code snippet:\n",
    "       IDENTIFICATION DIVISION.\n",
    "       PROGRAM-ID. Hello-World.\n",
    "       PROCEDURE DIVISION.\n",
    "       DISPLAY 'Hello, world!'.\n",
    "       STOP RUN.\n",
    "\n",
    "AI: \"Here is the equivalent Java code:\n",
    "public class HelloWorld {{\n",
    "    public static void main(String[] args) {{\n",
    "        System.out.println(\"Hello, world!\");\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Human: \"Can you explain what this JavaScript function does?\"\n",
    "\n",
    "AI: \"Of course! Here is the explanation for the JavaScript function:\n",
    "function add(a, b) {{\n",
    "    return a + b;\n",
    "}}\n",
    "'''\n",
    "\n",
    "PHI_VISION_TEMPLATE = '''You are an advanced AI model with the capability to analyze and interpret images as well as understand and respond to text-based queries. Your role is to assist users by providing detailed descriptions, analyses, and answers based on the visual and textual information provided. Follow these guidelines:\n",
    "\n",
    "1. **Image Analysis**:\n",
    "    - When an image is provided, analyze the image content thoroughly.\n",
    "    - Provide detailed descriptions of the objects, scenes, and any relevant context within the image.\n",
    "    - Identify and describe any text present in the image, if applicable.\n",
    "    - Answer questions related to the image content based on the visual information.\n",
    "\n",
    "2. **Text Queries**:\n",
    "    - When a text-based query is provided, respond with accurate and informative answers.\n",
    "    - If the query is related to the image, combine your visual analysis with textual information to provide a comprehensive response.\n",
    "\n",
    "3. **Combined Inputs**:\n",
    "    - When both an image and a text query are provided, use both inputs to generate a detailed and relevant response.\n",
    "    - Prioritize addressing the user's query by integrating insights from both the image and the text.\n",
    "\n",
    "4. **Clarification and Follow-up**:\n",
    "    - If the input is unclear or additional information is needed, politely ask the user for clarification.\n",
    "    - Offer follow-up assistance based on the user's initial query or image analysis.\n",
    "\n",
    "5. **User Assistance**:\n",
    "    - Always be polite, professional, and helpful in your responses.\n",
    "    - Aim to enhance the user's understanding and provide valuable insights.\n",
    "\n",
    "Example Input and Response:\n",
    "\n",
    "- **Input**: \n",
    "    - Text: \"What can you tell me about this image?\"\n",
    "    - Image: [Base64 encoded image]\n",
    "\n",
    "- **Response**:\n",
    "    \"The image shows a busy street in downtown Los Angeles with several people walking. The background features tall buildings, and there are various shops and cafes visible. The weather appears sunny, indicating it might be a typical warm day in Los Angeles. Is there anything specific you would like to know about the image?\"\n",
    "'''\n",
    "\n",
    "PROMPT_INFOS = [\n",
    "    {\n",
    "        'name': 'Text Assistant',\n",
    "\n",
    "        'description': 'An advanced AI model specialized in natural language understanding and generation. It assists users in tasks such as information retrieval, content creation, translation, sentiment analysis, and personalized recommendations. It also supports educational and healthcare-related queries, providing detailed explanations and preliminary assessments. This model ensures accurate and contextually relevant responses.',\n",
    "\n",
    "        'template': LLAMA_TEMPLATE\n",
    "    },\n",
    "    {\n",
    "        'name': 'Code Assistant',\n",
    "\n",
    "        'description': 'An advanced AI model specialized in code-related tasks. It assists users with generating, explaining, and fixing code, as well as automating documentation and testing. It excels in translating legacy code into modern languages and performing security analyses. This model is highly effective for modernizing applications and ensuring code quality.',\n",
    "        'template': GRANITE_TEMPLATE\n",
    "    },\n",
    "    {\n",
    "        'name': 'Vision Assistant',\n",
    "\n",
    "        'description': 'An advanced AI model with image analysis capabilities. It interprets images and text-based queries, providing detailed descriptions, analyses, and answers based on visual and textual information. It combines image and text inputs to generate comprehensive responses and offers assistance in understanding visual content.',\n",
    "        \n",
    "        'template': PHI_VISION_TEMPLATE\n",
    "    }\n",
    "]\n"
   ],
   "id": "470c7b20b08c5613",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining LLM Chat Models",
   "id": "5b19623e73f0754c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:21:58.902283Z",
     "start_time": "2024-06-16T09:21:58.899828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama_llm = ChatNVIDIA(model='meta/llama3-70b-instruct'),\n",
    "granite_llm = ChatNVIDIA(model='ibm/granite-34b-code-instruct')\n",
    "phi_vision_llm = ChatNVIDIA(model=\"microsoft/phi-3-vision-128k-instruct\")"
   ],
   "id": "c46d2603ee86c32e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define Destination Chains",
   "id": "baca8cccb26ea0b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:22:00.068537Z",
     "start_time": "2024-06-16T09:22:00.065294Z"
    }
   },
   "cell_type": "code",
   "source": "destination_chains = {}",
   "id": "c52cc0294cc48171",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:22:00.411871Z",
     "start_time": "2024-06-16T09:22:00.389032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama_chain = LLMChain(llm=llama_llm, prompt=ChatPromptTemplate.from_template(LLAMA_TEMPLATE))\n",
    "phi_vision_chain = LLMChain(llm=phi_vision_llm, prompt=ChatPromptTemplate.from_template(PHI_VISION_TEMPLATE))\n",
    "granite_chain = LLMChain(llm=granite_llm, prompt=ChatPromptTemplate.from_template(GRANITE_TEMPLATE))"
   ],
   "id": "c8bad437a447dcdf",
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m llama_chain \u001B[38;5;241m=\u001B[39m \u001B[43mLLMChain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mllama_llm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatPromptTemplate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_template\u001B[49m\u001B[43m(\u001B[49m\u001B[43mLLAMA_TEMPLATE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m phi_vision_chain \u001B[38;5;241m=\u001B[39m LLMChain(llm\u001B[38;5;241m=\u001B[39mphi_vision_llm, prompt\u001B[38;5;241m=\u001B[39mChatPromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(PHI_VISION_TEMPLATE))\n\u001B[1;32m      3\u001B[0m granite_chain \u001B[38;5;241m=\u001B[39m LLMChain(llm\u001B[38;5;241m=\u001B[39mgranite_llm, prompt\u001B[38;5;241m=\u001B[39mChatPromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(GRANITE_TEMPLATE))\n",
      "File \u001B[0;32m~/miniconda3/envs/vision/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:183\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    181\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    182\u001B[0m     emit_warning()\n\u001B[0;32m--> 183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/vision/lib/python3.10/site-packages/pydantic/main.py:341\u001B[0m, in \u001B[0;36mpydantic.main.BaseModel.__init__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValidationError\u001B[0m: 2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T08:25:44.245382Z",
     "start_time": "2024-06-16T08:25:44.114418Z"
    }
   },
   "cell_type": "code",
   "source": "import streamlit as st\n",
   "id": "c828bdbd9fe36da",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T08:26:13.017600Z",
     "start_time": "2024-06-16T08:26:12.979231Z"
    }
   },
   "cell_type": "code",
   "source": "image = st.file_uploader('Upload an image (for Phi Vision model only)', type=['jpg', 'jpeg', 'png'])\n",
   "id": "1e700b335c2c3f86",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 01:26:13.016 \n",
      "  \u001B[33m\u001B[1mWarning:\u001B[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/ganesh/miniconda3/envs/vision/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T08:26:18.184665Z",
     "start_time": "2024-06-16T08:26:18.181111Z"
    }
   },
   "cell_type": "code",
   "source": "type(image)",
   "id": "b332d0bafb50842e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "befe66429feff390"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "35f290e3ab53ad88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "326f55f4762801e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "96463e601fdc97d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T10:05:39.645172Z",
     "start_time": "2024-06-16T10:05:39.198811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Models\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llama = ChatNVIDIA(model='meta/llama3-70b-instruct')\n",
    "phi_vision = ChatNVIDIA(model='microsoft/phi-3-vision-128k-instruct')\n",
    "granite = ChatNVIDIA(model='ibm/granite-34b-code-instruct')\n",
    "\n",
    "# Wrap Models in LLMChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create prompts for each model\n",
    "llama_chain = LLMChain(llm=llama, prompt=ChatPromptTemplate.from_template(LLAMA_TEMPLATE))\n",
    "phi_vision_chain = LLMChain(llm=phi_vision, prompt=ChatPromptTemplate.from_template(PHI_VISION_TEMPLATE))\n",
    "granite_chain = LLMChain(llm=granite, prompt=ChatPromptTemplate.from_template(GRANITE_TEMPLATE))\n",
    "\n",
    "# Assign Chains to Destination Chains\n",
    "destination_chains = {\n",
    "    'Text Assistant': llama_chain,\n",
    "    'Vision Assistant': phi_vision_chain,\n",
    "    'Code Assistant': granite_chain\n",
    "}\n",
    "\n",
    "# Set Up Default Chain\n",
    "default_prompt = ChatPromptTemplate.from_template('{input}')\n",
    "default_chain = LLMChain(llm=llama, prompt=default_prompt)\n",
    "\n",
    "# Prepare Router Chain\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in PROMPT_INFOS]\n",
    "destination_str = '\\n'.join(destinations)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destination_str)\n",
    "router_prompt = PromptTemplate(template=router_template, input_variables=['input'], output_parser=RouterOutputParser())\n",
    "\n",
    "# Initialize Router Chain\n",
    "router_chain = LLMRouterChain.from_llm(llm=llama, prompt=router_prompt)\n",
    "\n",
    "# Create MultiPromptChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "f08aee46dfe2cab5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganesh/miniconda3/envs/vision/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T10:05:43.661801Z",
     "start_time": "2024-06-16T10:05:42.196856Z"
    }
   },
   "cell_type": "code",
   "source": "response = chain.run('What can you tell me about France?')",
   "id": "3c78f28b39941dd5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganesh/miniconda3/envs/vision/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "Text Assistant: {'input': 'What are some key facts about France?'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T10:05:46.985905Z",
     "start_time": "2024-06-16T10:05:46.980063Z"
    }
   },
   "cell_type": "code",
   "source": "response",
   "id": "3cc7d46c0be93f86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm ready to assist you with any task or query you may have. Please feel free to ask me anything, and I'll do my best to provide a helpful and accurate response.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5434893eb3706bed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
